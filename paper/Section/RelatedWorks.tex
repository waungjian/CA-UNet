\section{Related work}

\subsubsection{CNN-based methods}:
Due to the powerful characterization capability of deep CNNs, researchers applied them to medical image segmentation tasks and proposed U-Net~\cite{ronneberger2015u}. Due to the superior performance and generalization ability of U-shaped structure, various networks based on U-shaped structure have also been proposed successively, such as U-Net++~\cite{zhou2019unet++} and U-Net3+~\cite{huang2020unet}, which incorporate multiscale mechanism, and Residual U-Net~\cite{baldeon2020adaresu,alom2018nuclei,mostafiz2018retinal,li2019automatic}, which incorporates residual connectivity. Some researchers have also applied the structure to the field of 3D medical image segmentation, and 3D U-Net~\cite{cciccek20163d} and V-Net~\cite{milletari2016v} have been proposed successively.

\subsubsection{Attention mechanism}:
The visual attention mechanism holds crucial significance in deep learning technology research. Attention U-Net~\cite{oktay2018attention} was the first to introduce the gated visual attention mechanism, enhancing the modeling capability of complex relationships between features at different scales and levels. U-Net v2~\cite{peng2023u} combines the CBAM module with the cross-layer connections of U-Net architecture, endowing the decoder's multi-level feature maps with rich semantic information and complex detail features through attention focus.With the great success of Transformer on natural language processing, many researchers applied it to computer vision tasks and proposed ViT~\cite{dosovitskiy2020image}. It was applied to image recognition tasks and achieved comparable performance to CNN with large-scale data pre-training. To improve the applicability of Transformer for various vision tasks, Swin Transformer~\cite{liu2021swin} with a hierarchical structure was created to bring higher efficiency through a multi-scale modeling and shifted windowing scheme, demonstrating the potential of Transformer-based models as a visual backbone. Based on the excellent performance of Transformer on vision tasks, combined with the U-shaped architecture, researchers proposed Swin-UNet~\cite{cao2022swin} for medical semantic segmentation tasks and achieved excellent segmentation accuracy, providing a new perspective to solve the problem of medical semantic segmentation tasks. To further enhance the adaptive feature alignment ability of the Transformer, researchers optimized its structure, applied it to U-Net's network encoder, decoder, and skip connections for feature extraction, and proposed MISSFormer~\cite{huang2022missformer} for use in medical image segmentation tasks.

\subsubsection{Combining CNNs with Transformer}:
Due to the excellent performance of Transformer in the field of vision, researchers have endeavored to combine CNN with Transformer and exploit the complementary nature of both to build U-shaped encoder-decoder medical image segmentation models and improve the segmentation capability of the models, such as TransUNet~\cite{chen2021transunet} and TransFuse~\cite{zhang2021transfuse}. Different from the fusion approach of the above hybrid architecture models, we try to explore the potential of a novel structural fusion approach of hybrid architecture in medical image segmentation. In addition, leveraging the outstanding global modelling ability of Transformer, CASTformer~\cite{you2022class} has built a class-aware module based on the Transformer, which updates the sampling positions through iterative optimization, thereby adapting to the key areas of objects, such as anatomical features and structural information.



